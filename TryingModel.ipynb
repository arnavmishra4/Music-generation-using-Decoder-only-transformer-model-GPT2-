{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpretty_midi\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:2476\u001b[0m\n\u001b[0;32m   2472\u001b[0m     torch_module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;18m__name__\u001b[39m, device_type])\n\u001b[0;32m   2473\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[torch_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m-> 2476\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2477\u001b[0m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[0;32m   2478\u001b[0m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[0;32m   2479\u001b[0m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[0;32m   2480\u001b[0m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[0;32m   2481\u001b[0m )\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\__init__.py:64\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrictMinMaxConstraint\n\u001b[0;32m     44\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnflattenedModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m ]\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Constraint, Dim, dims, ShapesCollection\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_signature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     _get_node_type,\n\u001b[0;32m     13\u001b[0m     BUILTIN_TYPES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     tree_map_with_path,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Symbol\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\exported_program.py:26\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     Any,\n\u001b[0;32m     14\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     Union,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd_not_implemented\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_class_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeScriptObject\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m first_call_function_nn_module_stack\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcond\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     flex_attention,\n\u001b[0;32m      4\u001b[0m     flex_attention_backward,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhints_wrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hints_wrapper\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01minductor_config\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _functionalization_reapply_views_tls \u001b[38;5;28;01mas\u001b[39;00m _reapply_views\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_inductor\\config.py:44\u001b[0m\n\u001b[0;32m     40\u001b[0m verbose_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# use fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     43\u001b[0m fx_graph_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 44\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_fbcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# use remote fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# False: Disables the cache\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# True: Enables the cache\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001b[39;00m\n\u001b[0;32m     51\u001b[0m fx_graph_remote_cache: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m fx_graph_remote_cache_default()\n",
      "File \u001b[1;32mc:\\Users\\mishr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_inductor\\config.py:9\u001b[0m, in \u001b[0;36mis_fbcode\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_fbcode\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnxruntime\n",
    "import pretty_midi\n",
    "\n",
    "# Helper function to convert MIDI to text (as provided)\n",
    "def midi_to_text(midi_file):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    text_data = []\n",
    "    \n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            start_time = note.start\n",
    "            end_time = note.end\n",
    "            instrument_name = instrument.name if instrument.name else 'Unnamed'\n",
    "            note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "            start_beat = midi_data.get_beats(start_time)[0] if midi_data.get_beats(start_time) else 0\n",
    "            end_beat = midi_data.get_beats(end_time)[0] if midi_data.get_beats(end_time) else 0\n",
    "            note_value = note.pitch\n",
    "            duration = end_time - start_time  \n",
    "            velocity = note.velocity  \n",
    "            \n",
    "            text_line = f\"{start_time} {end_time} {instrument_name} {note_name} {start_beat} {end_beat} {note_value} {duration} {velocity}\"\n",
    "            text_data.append(text_line)\n",
    "    \n",
    "    return '\\n'.join(text_data)\n",
    "\n",
    "# Helper function to convert text back to MIDI (as provided)\n",
    "def text_to_midi(text_data):\n",
    "    midi_data = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)\n",
    "    \n",
    "    for line in text_data.split('\\n'):\n",
    "        start_time, end_time, instrument_name, note_name, start_beat, end_beat, note_value, duration, velocity = line.split()\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=int(velocity),\n",
    "            pitch=int(note_value),\n",
    "            start=float(start_time),\n",
    "            end=float(end_time)\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "    \n",
    "    midi_data.instruments.append(instrument)\n",
    "    return midi_data\n",
    "\n",
    "# Function to predict the next notes based on a text input\n",
    "def predict_next_notes(onnx_model_path, text_data, max_length=100):\n",
    "    # Load the ONNX model\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "    \n",
    "    # Tokenize the input text data\n",
    "    input_ids = tokenizer.encode(text_data, return_tensors=\"pt\")  # Ensure tokenizer is loaded in your environment\n",
    "\n",
    "    # Initialize the generated sequence\n",
    "    generated_ids = input_ids\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Run the model on the current sequence\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: generated_ids.numpy()}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "        \n",
    "        # Get the predicted next token and append it to the sequence\n",
    "        next_token_id = torch.argmax(torch.tensor(ort_outs[0]), dim=-1)[:, -1].unsqueeze(-1)\n",
    "        generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "        \n",
    "        # Stop if the model generates an end-of-sequence token (check for EOS token, if defined)\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    # Decode the generated sequence back to text\n",
    "    predicted_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return predicted_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Load a MIDI file, predict next notes, and convert back to MIDI\n",
    "midi_file_path = \"path_to_your_midi_file.mid\"\n",
    "onnx_model_path = \"fine_tuned_gpt2.onnx\"\n",
    "\n",
    "# Convert the MIDI file to text format\n",
    "text_data = midi_to_text(midi_file_path)\n",
    "\n",
    "# Predict the next notes in text format\n",
    "predicted_text = predict_next_notes(onnx_model_path, text_data)\n",
    "\n",
    "# Convert the predicted text back to MIDI format\n",
    "predicted_midi = text_to_midi(predicted_text)\n",
    "\n",
    "# Save the generated MIDI\n",
    "predicted_midi.save(\"predicted_output.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
